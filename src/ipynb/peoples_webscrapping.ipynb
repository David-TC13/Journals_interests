{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from datetime import datetime\n",
    "\n",
    "import googletrans\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re as re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from langdetect import detect\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword(word, no_news):\n",
    "    \n",
    "    url= 'http://en.people.cn'\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    cookies_button_deny  = driver.find_element(By.CLASS_NAME,'tipsClose').click()\n",
    "\n",
    "    form = driver.find_element(By.NAME,\"searchFormForPC\")\n",
    "    keyword_input = form.find_element(By.NAME,\"keyword\")\n",
    "    keyword_input.send_keys(word)\n",
    "    keyword_input.send_keys(Keys.RETURN)\n",
    "    driver.close()\n",
    "    \n",
    "    driver.switch_to.window( driver.window_handles[0])\n",
    "    \n",
    "    link_lst=[]\n",
    "    \n",
    "    while len(link_lst)<no_news:\n",
    "\n",
    "        lnks          = driver.find_elements(By.TAG_NAME,\"a\")\n",
    "        lst_pc        = [lnk.get_attribute('href') for lnk in lnks]\n",
    "        lst_pc_       = [url for url in lst_pc if '/2023' in url or '/2022'in url]\n",
    "        for i in lst_pc_:\n",
    "            link_lst.append(i)\n",
    "            \n",
    "        link_lst= list(set(link_lst))\n",
    "\n",
    "        list_soup=[]\n",
    "        list_title=[]\n",
    "\n",
    "        for url in link_lst:\n",
    "            html    = requests.get(url)\n",
    "            soup    = BeautifulSoup(html.content, \"html.parser\")\n",
    "            title   = soup.title.string.strip()\n",
    "            article = soup.getText()\n",
    "            article = article[:article.find('(Web editor')]\n",
    "            article = article[article.find('>>'):]\n",
    "            article=article.replace('\\n','').replace('\\t','').replace('\\'s',\"Â´s\").replace('>>',\"\")\n",
    "            list_soup.append(article)\n",
    "            list_title.append(title)\n",
    "            \n",
    "\n",
    "        day_list=[]\n",
    "        month_list=[]\n",
    "        year_list=[]\n",
    "        for url in link_lst:\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            date_div = soup.find('div', class_='origin')\n",
    "            date_str = date_div.span.text.strip()\n",
    "\n",
    "            hour, month_day, year = date_str.split(\", \")[-3:]\n",
    "            month_str, day = month_day.split(\" \")\n",
    "\n",
    "            months_dict = {\n",
    "                'January': 1,\n",
    "                'February': 2,\n",
    "                'March': 3,\n",
    "                'April': 4,\n",
    "                'May': 5,\n",
    "                'June': 6,\n",
    "                'July': 7,\n",
    "                'August': 8,\n",
    "                'September': 9,\n",
    "                'October': 10,\n",
    "                'November': 11,\n",
    "                'December': 12\n",
    "            }\n",
    "            month_int = months_dict[month_str]\n",
    "\n",
    "            day_list.append(day)\n",
    "            month_list.append(month_int)\n",
    "            year_list.append(year)\n",
    "            \n",
    "            try:\n",
    "                next_button = driver.find_element(By.LINK_TEXT, 'Next').click()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    dict_pc={'title': list_title,\n",
    "         'article':list_soup,\n",
    "         'link': link_lst,\n",
    "         'day':day_list,\n",
    "         'month':month_list,\n",
    "         'year':year_list\n",
    "            }\n",
    "    df_cn= pd.DataFrame(dict_pc)\n",
    "    driver.close()\n",
    "   \n",
    "    return df_cn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
